{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11075,"status":"ok","timestamp":1712910815054,"user":{"displayName":"이규진","userId":"15581271079389640736"},"user_tz":-540},"id":"8gGCYPotLkZ9"},"outputs":[],"source":["import transformers\n","from transformers import ElectraModel, ElectraTokenizer\n","import torch\n","import pandas as pd\n","import torch.nn as nn\n","import random\n","import os\n","from transformers.optimization import get_cosine_schedule_with_warmup"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# 코랩에서 실행\n","# from google.colab import drive\n","# drive.mount('content/gdrive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"T6tBFBAqdGmP"},"outputs":[],"source":["# !pip install Korpora\n","# !git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n","\n","# %cd Mecab-ko-for-Google-Colab/\n","\n","# !bash install_mecab-ko_on_colab_light_220429.sh\n","\n","# from konlpy.tag import Mecab\n","\n","# tokenizer_mecab = Mecab()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"9F6HCwP-cO2N"},"outputs":[],"source":["# from konlpy.tag import Komoran\n","\n","# komoran = Komoran()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["daf3ecf0f3af4c14b5f11cafddbec554","68228df6dc3e4431b453433f094ade57","5d6a39fbb4e54109997b36e1ea89c066","67a25503df62410d9be2d53a6843ee72","2ea8c57d705541bcbe2452a362184c88","2ab76aaf83c540a48c35e437cb970469","72a6ab83e2154eb4ba323be7b76a062e","c8ca25f545f64ca4b9d9e1e3d9ca7a00","413de6e14f4c4ca6918c6a4da73344b1","1b8e4c6c3c6d4c7fbbe24491359368dc","cb00bd2d99ea42d782f8a11cf3fef67e","e67e20811b1b46cab49c53fd7f637cb7","4cbc4b661d654faba6eed53a4f1c3311","4ec3f2babc22420f9b444a33c2a1561f","bb5672b789f2412bbf49a4734df87b81","a34d8583a1f242b5988f03c670e34fc7","c009bca84fa94198bcc7484f813ba180","419afa4fb53f454ba2a75ba00229813e","3533324b7a9f41578022594bdac952b4","1f5d7f0499cf491f8f28c305a97d5f60","0ec35b2122bf453f97c4f1319d73b193","4c0d7bb96d9e46b4b3b2d4ae91c92786","d3ab91b745f0493fb7ecfd17aa22e723","cd2ea341f6384982baa3f07244a4e72a","047ea13f87e24cac9a8de2b15e6b1ae9","ad6b3720d9ec4d5c997072d2eea8b038","c4197f81b72c4b5982944b5d8928f05a","cea73f88dcae4810ab3b2085128f8b43","f27d6e04a7fd4d368e971b8750a7b320","89a250eaa65c4eb0a749b16556b1dec9","c4205cb5af98411fa8a1346bcb430f15","082a56007a704911b531b31c388cea10","d94f3cce2a5c46fb8aaa1064d0e82aab"]},"executionInfo":{"elapsed":1671,"status":"ok","timestamp":1712912122852,"user":{"displayName":"이규진","userId":"15581271079389640736"},"user_tz":-540},"id":"7fChtn7uPCM4","outputId":"f666f45f-f893-46b4-b4cd-79252a507c2a"},"outputs":[],"source":["electra_version = 'base-v3' # can be base / small / base-v2 / small-v2 / base-v3 / small-v3 바꾸면 맨 위에 tokenizer도 바꿔줘야함\n","tokenizer = ElectraTokenizer.from_pretrained(f\"monologg/koelectra-{electra_version}-discriminator\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":350,"status":"ok","timestamp":1712910856775,"user":{"displayName":"이규진","userId":"15581271079389640736"},"user_tz":-540},"id":"mszlJFCkUmzl","outputId":"d64b8fce-c74e-45d6-94fd-c519f13e16d1"},"outputs":[],"source":["# from google.colab import files\n","# import chardet\n","\n","# with open('kodoli_v1.1.csv', 'rb') as rawdata:\n","#     result = chardet.detect(rawdata.read(10000))\n","\n","# # check what the character encoding might be\n","# print(result)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4651,"status":"ok","timestamp":1712912129778,"user":{"displayName":"이규진","userId":"15581271079389640736"},"user_tz":-540},"id":"Vz3nSWamU6EJ"},"outputs":[],"source":["# 데이터 받아서 문장 앞 뒤에 class 토큰 seperate 토큰 넣어주기\n","df = pd.read_csv('kodoli_v1.1.csv', encoding='CP949')\n","data_size = len(df)\n","data_list = []\n","for i in range(data_size):\n","  data_list.append(list(df.iloc[i, 1:5]))\n","for i in range(data_size):\n","  data_list[i][0] = '[CLS] ' + data_list[i][0] + ' [SEP]'"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6458,"status":"ok","timestamp":1712912136235,"user":{"displayName":"이규진","userId":"15581271079389640736"},"user_tz":-540},"id":"r4AC89wT89hJ","outputId":"c10deda3-16c7-45c1-e7de-0a477a492d0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["N of Seq with len1 : 0 / cumulative rate: 0.0%\n","N of Seq with len2 : 0 / cumulative rate: 0.0%\n","N of Seq with len3 : 81 / cumulative rate: 0.21218074656188607%\n","N of Seq with len4 : 134 / cumulative rate: 0.5631958087753766%\n","N of Seq with len5 : 527 / cumulative rate: 1.9436804191224626%\n","N of Seq with len6 : 969 / cumulative rate: 4.4819908316961365%\n","N of Seq with len7 : 1227 / cumulative rate: 7.696136214800261%\n","N of Seq with len8 : 1634 / cumulative rate: 11.976424361493123%\n","N of Seq with len9 : 1931 / cumulative rate: 17.034708578912902%\n","N of Seq with len10 : 2080 / cumulative rate: 22.48330058939096%\n","N of Seq with len11 : 2150 / cumulative rate: 28.115258677144727%\n","N of Seq with len12 : 2119 / cumulative rate: 33.66601178781926%\n","N of Seq with len13 : 2033 / cumulative rate: 38.99148657498363%\n","N of Seq with len14 : 2007 / cumulative rate: 44.24885396201702%\n","N of Seq with len15 : 1873 / cumulative rate: 49.155206286836936%\n","N of Seq with len16 : 1708 / cumulative rate: 53.62933857236412%\n","N of Seq with len17 : 1661 / cumulative rate: 57.98035363457761%\n","N of Seq with len18 : 1411 / cumulative rate: 61.676489849377866%\n","N of Seq with len19 : 1220 / cumulative rate: 64.87229862475442%\n","N of Seq with len20 : 1037 / cumulative rate: 67.5887360838245%\n","N of Seq with len21 : 898 / cumulative rate: 69.9410609037328%\n","N of Seq with len22 : 744 / cumulative rate: 71.88998035363457%\n","N of Seq with len23 : 633 / cumulative rate: 73.54813359528487%\n","N of Seq with len24 : 599 / cumulative rate: 75.11722331368696%\n","N of Seq with len25 : 533 / cumulative rate: 76.51342501637197%\n","N of Seq with len26 : 460 / cumulative rate: 77.71840209561232%\n","N of Seq with len27 : 442 / cumulative rate: 78.8762278978389%\n","N of Seq with len28 : 410 / cumulative rate: 79.95022920759659%\n","N of Seq with len29 : 359 / cumulative rate: 80.89063523248198%\n","N of Seq with len30 : 377 / cumulative rate: 81.87819253438114%\n","N of Seq with len31 : 321 / cumulative rate: 82.71905697445973%\n","N of Seq with len32 : 288 / cumulative rate: 83.47347740667976%\n","N of Seq with len33 : 281 / cumulative rate: 84.20956123117223%\n","N of Seq with len34 : 264 / cumulative rate: 84.9011132940406%\n","N of Seq with len35 : 226 / cumulative rate: 85.49312377210217%\n","N of Seq with len36 : 237 / cumulative rate: 86.1139489194499%\n","N of Seq with len37 : 212 / cumulative rate: 86.66928618205631%\n","N of Seq with len38 : 194 / cumulative rate: 87.17747216764899%\n","N of Seq with len39 : 231 / cumulative rate: 87.78258022265881%\n","N of Seq with len40 : 170 / cumulative rate: 88.2278978388998%\n","N of Seq with len41 : 179 / cumulative rate: 88.69679109364768%\n","N of Seq with len42 : 156 / cumulative rate: 89.10543549443352%\n","N of Seq with len43 : 184 / cumulative rate: 89.58742632612967%\n","N of Seq with len44 : 162 / cumulative rate: 90.01178781925344%\n","N of Seq with len45 : 135 / cumulative rate: 90.36542239685657%\n","N of Seq with len46 : 149 / cumulative rate: 90.75573018991486%\n","N of Seq with len47 : 114 / cumulative rate: 91.0543549443353%\n","N of Seq with len48 : 109 / cumulative rate: 91.33988212180746%\n","N of Seq with len49 : 136 / cumulative rate: 91.69613621480026%\n","N of Seq with len50 : 123 / cumulative rate: 92.01833660772756%\n","N of Seq with len51 : 108 / cumulative rate: 92.30124426981008%\n","N of Seq with len52 : 112 / cumulative rate: 92.59462999345122%\n","N of Seq with len53 : 93 / cumulative rate: 92.83824492468892%\n","N of Seq with len54 : 89 / cumulative rate: 93.07138179436805%\n","N of Seq with len55 : 109 / cumulative rate: 93.35690897184021%\n","N of Seq with len56 : 83 / cumulative rate: 93.5743287491814%\n","N of Seq with len57 : 90 / cumulative rate: 93.81008513425016%\n","N of Seq with len58 : 85 / cumulative rate: 94.03274394237067%\n","N of Seq with len59 : 73 / cumulative rate: 94.22396856581531%\n","N of Seq with len60 : 85 / cumulative rate: 94.44662737393583%\n","N of Seq with len61 : 70 / cumulative rate: 94.62999345121152%\n","N of Seq with len62 : 74 / cumulative rate: 94.82383759004584%\n","N of Seq with len63 : 80 / cumulative rate: 95.03339882121807%\n","N of Seq with len64 : 63 / cumulative rate: 95.19842829076622%\n","N of Seq with len65 : 63 / cumulative rate: 95.36345776031435%\n","N of Seq with len66 : 62 / cumulative rate: 95.52586771447282%\n","N of Seq with len67 : 63 / cumulative rate: 95.69089718402095%\n","N of Seq with len68 : 58 / cumulative rate: 95.84282907662083%\n","N of Seq with len69 : 57 / cumulative rate: 95.99214145383104%\n","N of Seq with len70 : 60 / cumulative rate: 96.14931237721022%\n","N of Seq with len71 : 51 / cumulative rate: 96.28290766208252%\n","N of Seq with len72 : 63 / cumulative rate: 96.44793713163065%\n","N of Seq with len73 : 56 / cumulative rate: 96.5946299934512%\n","N of Seq with len74 : 54 / cumulative rate: 96.73608382449247%\n","N of Seq with len75 : 42 / cumulative rate: 96.8461034708579%\n","N of Seq with len76 : 38 / cumulative rate: 96.9456450556647%\n","N of Seq with len77 : 44 / cumulative rate: 97.06090373280944%\n","N of Seq with len78 : 36 / cumulative rate: 97.15520628683694%\n","N of Seq with len79 : 37 / cumulative rate: 97.2521283562541%\n","N of Seq with len80 : 27 / cumulative rate: 97.32285527177473%\n","N of Seq with len81 : 43 / cumulative rate: 97.4354944335298%\n","N of Seq with len82 : 28 / cumulative rate: 97.50884086444009%\n","N of Seq with len83 : 22 / cumulative rate: 97.56647020301244%\n","N of Seq with len84 : 31 / cumulative rate: 97.64767518009168%\n","N of Seq with len85 : 29 / cumulative rate: 97.72364112639161%\n","N of Seq with len86 : 19 / cumulative rate: 97.77341191879503%\n","N of Seq with len87 : 27 / cumulative rate: 97.84413883431566%\n","N of Seq with len88 : 14 / cumulative rate: 97.8808120497708%\n","N of Seq with len89 : 21 / cumulative rate: 97.9358218729535%\n","N of Seq with len90 : 20 / cumulative rate: 97.98821218074656%\n","N of Seq with len91 : 16 / cumulative rate: 98.03012442698102%\n","N of Seq with len92 : 20 / cumulative rate: 98.08251473477407%\n","N of Seq with len93 : 14 / cumulative rate: 98.1191879502292%\n","N of Seq with len94 : 15 / cumulative rate: 98.158480681074%\n","N of Seq with len95 : 15 / cumulative rate: 98.1977734119188%\n","N of Seq with len96 : 19 / cumulative rate: 98.2475442043222%\n","N of Seq with len97 : 18 / cumulative rate: 98.29469548133595%\n","N of Seq with len98 : 16 / cumulative rate: 98.3366077275704%\n","N of Seq with len99 : 12 / cumulative rate: 98.36804191224623%\n","N of Seq with len100 : 14 / cumulative rate: 98.40471512770137%\n","N of Seq with len101 : 20 / cumulative rate: 98.45710543549443%\n","N of Seq with len102 : 17 / cumulative rate: 98.50163719711853%\n","N of Seq with len103 : 12 / cumulative rate: 98.53307138179437%\n","N of Seq with len104 : 11 / cumulative rate: 98.56188605108055%\n","N of Seq with len105 : 16 / cumulative rate: 98.603798297315%\n","N of Seq with len106 : 13 / cumulative rate: 98.6378519973805%\n","N of Seq with len107 : 13 / cumulative rate: 98.67190569744596%\n","N of Seq with len108 : 12 / cumulative rate: 98.70333988212181%\n","N of Seq with len109 : 14 / cumulative rate: 98.74001309757695%\n","N of Seq with len110 : 11 / cumulative rate: 98.76882776686313%\n","N of Seq with len111 : 10 / cumulative rate: 98.79502292075966%\n","N of Seq with len112 : 13 / cumulative rate: 98.82907662082515%\n","N of Seq with len113 : 7 / cumulative rate: 98.84741322855271%\n","N of Seq with len114 : 17 / cumulative rate: 98.89194499017681%\n","N of Seq with len115 : 6 / cumulative rate: 98.90766208251473%\n","N of Seq with len116 : 6 / cumulative rate: 98.92337917485266%\n","N of Seq with len117 : 9 / cumulative rate: 98.94695481335954%\n","N of Seq with len118 : 9 / cumulative rate: 98.9705304518664%\n","N of Seq with len119 : 9 / cumulative rate: 98.99410609037328%\n","N of Seq with len120 : 8 / cumulative rate: 99.0150622134905%\n","N of Seq with len121 : 10 / cumulative rate: 99.04125736738703%\n","N of Seq with len122 : 2 / cumulative rate: 99.04649639816634%\n","N of Seq with len123 : 8 / cumulative rate: 99.06745252128356%\n","N of Seq with len124 : 5 / cumulative rate: 99.08055009823183%\n","N of Seq with len125 : 4 / cumulative rate: 99.09102815979044%\n","N of Seq with len126 : 2 / cumulative rate: 99.09626719056975%\n","N of Seq with len127 : 9 / cumulative rate: 99.11984282907662%\n","N of Seq with len128 : 8 / cumulative rate: 99.14079895219385%\n","N of Seq with len129 : 3 / cumulative rate: 99.14865749836281%\n","N of Seq with len130 : 6 / cumulative rate: 99.16437459070072%\n","N of Seq with len131 : 11 / cumulative rate: 99.19318925998691%\n","N of Seq with len132 : 8 / cumulative rate: 99.21414538310412%\n","N of Seq with len133 : 6 / cumulative rate: 99.22986247544205%\n","N of Seq with len134 : 6 / cumulative rate: 99.24557956777996%\n","N of Seq with len135 : 9 / cumulative rate: 99.26915520628684%\n","N of Seq with len136 : 3 / cumulative rate: 99.2770137524558%\n","N of Seq with len137 : 4 / cumulative rate: 99.2874918140144%\n","N of Seq with len138 : 7 / cumulative rate: 99.30582842174198%\n","N of Seq with len139 : 8 / cumulative rate: 99.32678454485921%\n","N of Seq with len140 : 14 / cumulative rate: 99.36345776031435%\n","N of Seq with len141 : 5 / cumulative rate: 99.3765553372626%\n","N of Seq with len142 : 8 / cumulative rate: 99.39751146037983%\n","N of Seq with len143 : 3 / cumulative rate: 99.4053700065488%\n","N of Seq with len144 : 7 / cumulative rate: 99.42370661427637%\n","N of Seq with len145 : 6 / cumulative rate: 99.43942370661428%\n","N of Seq with len146 : 4 / cumulative rate: 99.4499017681729%\n","N of Seq with len147 : 7 / cumulative rate: 99.46823837590046%\n","N of Seq with len148 : 1 / cumulative rate: 99.47085789129011%\n","N of Seq with len149 : 9 / cumulative rate: 99.49443352979699%\n","N of Seq with len150 : 4 / cumulative rate: 99.5049115913556%\n","N of Seq with len151 : 13 / cumulative rate: 99.53896529142109%\n","N of Seq with len152 : 7 / cumulative rate: 99.55730189914865%\n","N of Seq with len153 : 4 / cumulative rate: 99.56777996070727%\n","N of Seq with len154 : 13 / cumulative rate: 99.60183366077275%\n","N of Seq with len155 : 7 / cumulative rate: 99.62017026850033%\n","N of Seq with len156 : 7 / cumulative rate: 99.6385068762279%\n","N of Seq with len157 : 6 / cumulative rate: 99.65422396856582%\n","N of Seq with len158 : 7 / cumulative rate: 99.67256057629339%\n","N of Seq with len159 : 7 / cumulative rate: 99.69089718402095%\n","N of Seq with len160 : 6 / cumulative rate: 99.70661427635888%\n","N of Seq with len161 : 8 / cumulative rate: 99.7275703994761%\n","N of Seq with len162 : 9 / cumulative rate: 99.75114603798298%\n","N of Seq with len163 : 10 / cumulative rate: 99.7773411918795%\n","N of Seq with len164 : 6 / cumulative rate: 99.79305828421742%\n","N of Seq with len165 : 11 / cumulative rate: 99.8218729535036%\n","N of Seq with len166 : 14 / cumulative rate: 99.85854616895874%\n","N of Seq with len167 : 7 / cumulative rate: 99.87688277668632%\n","N of Seq with len168 : 6 / cumulative rate: 99.89259986902424%\n","N of Seq with len169 : 4 / cumulative rate: 99.90307793058284%\n","N of Seq with len170 : 2 / cumulative rate: 99.90831696136215%\n","N of Seq with len171 : 1 / cumulative rate: 99.9109364767518%\n","N of Seq with len172 : 6 / cumulative rate: 99.92665356908972%\n","N of Seq with len173 : 3 / cumulative rate: 99.93451211525868%\n","N of Seq with len174 : 2 / cumulative rate: 99.93975114603798%\n","N of Seq with len175 : 5 / cumulative rate: 99.95284872298625%\n","N of Seq with len176 : 1 / cumulative rate: 99.9554682383759%\n","N of Seq with len177 : 1 / cumulative rate: 99.95808775376555%\n","N of Seq with len178 : 1 / cumulative rate: 99.96070726915521%\n","N of Seq with len179 : 1 / cumulative rate: 99.96332678454486%\n","N of Seq with len180 : 1 / cumulative rate: 99.96594629993452%\n","N of Seq with len181 : 1 / cumulative rate: 99.96856581532415%\n","N of Seq with len182 : 1 / cumulative rate: 99.97118533071382%\n","N of Seq with len183 : 1 / cumulative rate: 99.97380484610348%\n","N of Seq with len184 : 1 / cumulative rate: 99.97642436149312%\n","N of Seq with len185 : 1 / cumulative rate: 99.97904387688278%\n","N of Seq with len186 : 2 / cumulative rate: 99.98428290766208%\n","N of Seq with len187 : 0 / cumulative rate: 99.98428290766208%\n","N of Seq with len188 : 1 / cumulative rate: 99.98690242305173%\n","N of Seq with len189 : 0 / cumulative rate: 99.98690242305173%\n","N of Seq with len190 : 0 / cumulative rate: 99.98690242305173%\n","N of Seq with len191 : 0 / cumulative rate: 99.98690242305173%\n","N of Seq with len192 : 0 / cumulative rate: 99.98690242305173%\n","N of Seq with len193 : 0 / cumulative rate: 99.98690242305173%\n","N of Seq with len194 : 0 / cumulative rate: 99.98690242305173%\n","N of Seq with len195 : 0 / cumulative rate: 99.98690242305173%\n","N of Seq with len196 : 0 / cumulative rate: 99.98690242305173%\n","N of Seq with len197 : 0 / cumulative rate: 99.98690242305173%\n","N of Seq with len198 : 1 / cumulative rate: 99.98952193844138%\n","N of Seq with len199 : 1 / cumulative rate: 99.99214145383104%\n","N of Seq with len200 : 0 / cumulative rate: 99.99214145383104%\n","N of Seq with len201 : 0 / cumulative rate: 99.99214145383104%\n","N of Seq with len202 : 2 / cumulative rate: 99.99738048461035%\n","N of Seq with len203 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len204 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len205 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len206 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len207 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len208 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len209 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len210 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len211 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len212 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len213 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len214 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len215 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len216 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len217 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len218 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len219 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len220 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len221 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len222 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len223 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len224 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len225 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len226 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len227 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len228 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len229 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len230 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len231 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len232 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len233 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len234 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len235 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len236 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len237 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len238 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len239 : 0 / cumulative rate: 99.99738048461035%\n","N of Seq with len240 : 1 / cumulative rate: 100.0%\n","N of Seq with len241 : 0 / cumulative rate: 100.0%\n","N of Seq with len242 : 0 / cumulative rate: 100.0%\n","N of Seq with len243 : 0 / cumulative rate: 100.0%\n","N of Seq with len244 : 0 / cumulative rate: 100.0%\n","N of Seq with len245 : 0 / cumulative rate: 100.0%\n","N of Seq with len246 : 0 / cumulative rate: 100.0%\n","N of Seq with len247 : 0 / cumulative rate: 100.0%\n","N of Seq with len248 : 0 / cumulative rate: 100.0%\n","N of Seq with len249 : 0 / cumulative rate: 100.0%\n"]}],"source":["# 문장 토큰 개수 분포\n","len_list = [0 for i in range(250)]\n","for data in data_list:\n","  lenOfSen = len(tokenizer.tokenize(data[0]))\n","  len_list[lenOfSen] += 1\n","sum = 0\n","for i in range(1, 250):\n","  sum += len_list[i]\n","  print(f'N of Seq with len{i} : {len_list[i]} / cumulative rate: {sum / data_size *100}%')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# data의 약 95%를 수용하는 길이인 64로 설정해서 64보다 많은 토큰이 있는 data는 버리기\n","max_length = 64\n","# label들을 숫자로 바꿔주기\n","abuse_dict = {'NON': 0, 'ABS' : 1}\n","sentiment_dict = {'NEG': 0, 'NEU': 1, 'POS': 2}\n","offensive_dict = {'NOT': 0, 'LIKELY': 1, 'OFFEN': 2}\n","# 모든 문장을 토큰화하고 숫자로 바꾼다. max length 보다 작은 문장은 pad 토큰을 넣어준다.\n","sentence_ids_list = []\n","attn_masks_list = []\n","labels_list = []\n","\n","for i in range(38175):\n","  temp = []\n","  tokened = tokenizer.tokenize(data_list[i][0])\n","  idx = tokenizer.convert_tokens_to_ids(tokened)\n","  idx_len = len(idx)\n","  attention_mask = [1 for i in range(idx_len)]\n","  if idx_len <= max_length:\n","    num_pad = max_length - idx_len\n","    for j in range(num_pad):\n","      idx.append(0)\n","      attention_mask.append(0)\n","  else: # max length 보다 긴 건 데이터셋에 안 넣기\n","    continue\n","  sentence_ids_list.append(idx)\n","  attn_masks_list.append(attention_mask)\n","  temp.append(abuse_dict[data_list[i][1]])\n","  temp.append(sentiment_dict[data_list[i][2]])\n","  temp.append(offensive_dict[data_list[i][3]])\n","  labels_list.append(temp)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# train / test 데이터셋 나누기\n","\n","test_data_percent = 10\n","\n","total_data_size = len(sentence_ids_list) #36,342\n","test_data_size = int(total_data_size * (test_data_percent / 100)) #3,634 10% test data\n","train_data_size = total_data_size - test_data_size #32,708 90% train data\n","\n","train_sentence_ids_list = torch.tensor(sentence_ids_list[:train_data_size])\n","test_sentence_ids_list = torch.tensor(sentence_ids_list[train_data_size:])\n","train_attn_masks_list = torch.tensor(attn_masks_list[:train_data_size])\n","test_attn_masks_list = torch.tensor(attn_masks_list[train_data_size:])\n","train_labels_list = torch.tensor(labels_list[:train_data_size])\n","test_labels_list = torch.tensor(labels_list[train_data_size:])"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["batch_size = 64\n","\n","train_data = torch.utils.data.TensorDataset(train_sentence_ids_list, train_attn_masks_list, train_labels_list)\n","train_sampler = torch.utils.data.RandomSampler(train_data)\n","train_dataloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","test_data = torch.utils.data.TensorDataset(test_sentence_ids_list, test_attn_masks_list, test_labels_list)\n","test_sampler = torch.utils.data.RandomSampler(test_data)\n","test_dataloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1712910895259,"user":{"displayName":"이규진","userId":"15581271079389640736"},"user_tz":-540},"id":"JRcZ6BcgI8Eq"},"outputs":[],"source":["class Classifier(nn.Module):\n","  def __init__(self, c_in, c_out):\n","    super().__init__()\n","    self.dropout = nn.Dropout(p = 0.5)\n","    self.fc1 = nn.Linear(c_in, c_out)\n","    self.norm = nn.LayerNorm(c_out)\n","    self.activation = nn.ReLU()\n","    self.init_weights()\n","\n","  def forward(self, x):\n","    x = self.dropout(x)\n","    return self.activation(self.norm(self.fc1(x)))\n","\n","  def init_weights(self):\n","    torch.nn.init.kaiming_normal_(self.fc1.weight.data)\n","    torch.nn.init.zeros_(self.fc1.bias.data)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["class NLPteam2_KoElectra(nn.Module):\n","    def __init__(self, electra_version = 'base-v3', num_hiddens = 256):\n","        super().__init__()\n","        self.electra = ElectraModel.from_pretrained(f\"monologg/koelectra-{electra_version}-discriminator\")\n","        electra_out_dim = 768 if 'base' in electra_version else 256\n","        \n","        self.abu_c1 = Classifier(electra_out_dim, 2)\n","        self.senti_c1 = Classifier(electra_out_dim, 3)\n","        self.off_c1 = Classifier(electra_out_dim, 3)\n","\n","        for param in list(self.electra.named_parameters()):\n","            if '10' in param[0]:\n","                break\n","            param[1].requires_grad = False\n","\n","    def forward(self, x, attention_mask):\n","        out = self.electra(x, attention_mask = attention_mask)\n","        cls_representation = out[0][:, 0, :]\n","        #cls_representation = torch.mean(out[0], dim=1)\n","        \n","        tmp_a = self.abu_c1(cls_representation)\n","        tmp_s = self.senti_c1(cls_representation)\n","        tmp_o = self.off_c1(cls_representation)\n","        \n","        # abu_pred = self.abu_c3(self.abu_c2(tmp_a))\n","        # senti_pred = self.senti_c3(self.senti_c2(tmp_s))\n","        # off_pred = self.off_c3(self.off_c2(tmp_o))\n","\n","        # abu_pred = self.abu_c2(tmp_a)\n","        # senti_pred = self.senti_c2(tmp_s)\n","        # off_pred = self.off_c2(tmp_o)       \n","        \n","        # return (abu_pred, senti_pred, off_pred)\n","        return (tmp_a, tmp_s, tmp_o)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1712912144701,"user":{"displayName":"이규진","userId":"15581271079389640736"},"user_tz":-540},"id":"QJNKrjE-RAmW"},"outputs":[],"source":["# # train / test 데이터셋 나누기\n","\n","# test_data_percent = 20\n","\n","# total_data_size = len(token_data_list) #36342\n","# test_data_size = int(total_data_size * (test_data_percent / 100)) #7268 20% test data\n","# train_data_size = total_data_size - test_data_size #29074 80% train data\n","# train_data = token_data_list[:train_data_size]\n","# test_data = token_data_list[train_data_size:]"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":547,"status":"ok","timestamp":1712912077358,"user":{"displayName":"이규진","userId":"15581271079389640736"},"user_tz":-540},"id":"7_oZTs4RIn5b"},"outputs":[],"source":["#torch.manual_seed(42)\n","max_epochs = 20\n","max_step_per_epoch = None\n","lr = 1e-3\n","num_hiddens = 512 # classifier hidden dim\n","electra_version = 'base-v3' # can be base / small / base-v2 / small-v2 / base-v3 / small-v3\n","saved_model_name = None # 불러올 모델 저장한 파일명\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","model = NLPteam2_KoElectra(electra_version=electra_version, num_hiddens=num_hiddens)\n","if saved_model_name:\n","    model.load_state_dict(torch.load(os.getcwd() + f'/{saved_model_name}.pth'))    \n","model.to(device)\n","\n","warmup_ratio = 0.1\n","t_total = len(train_dataloader) * max_epochs\n","warmup_step = int(t_total * warmup_ratio)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = warmup_step, num_training_steps = t_total)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["['electra.encoder.layer.10.attention.self.query.weight',\n"," 'electra.encoder.layer.10.attention.self.query.bias',\n"," 'electra.encoder.layer.10.attention.self.key.weight',\n"," 'electra.encoder.layer.10.attention.self.key.bias',\n"," 'electra.encoder.layer.10.attention.self.value.weight',\n"," 'electra.encoder.layer.10.attention.self.value.bias',\n"," 'electra.encoder.layer.10.attention.output.dense.weight',\n"," 'electra.encoder.layer.10.attention.output.dense.bias',\n"," 'electra.encoder.layer.10.attention.output.LayerNorm.weight',\n"," 'electra.encoder.layer.10.attention.output.LayerNorm.bias',\n"," 'electra.encoder.layer.10.intermediate.dense.weight',\n"," 'electra.encoder.layer.10.intermediate.dense.bias',\n"," 'electra.encoder.layer.10.output.dense.weight',\n"," 'electra.encoder.layer.10.output.dense.bias',\n"," 'electra.encoder.layer.10.output.LayerNorm.weight',\n"," 'electra.encoder.layer.10.output.LayerNorm.bias',\n"," 'electra.encoder.layer.11.attention.self.query.weight',\n"," 'electra.encoder.layer.11.attention.self.query.bias',\n"," 'electra.encoder.layer.11.attention.self.key.weight',\n"," 'electra.encoder.layer.11.attention.self.key.bias',\n"," 'electra.encoder.layer.11.attention.self.value.weight',\n"," 'electra.encoder.layer.11.attention.self.value.bias',\n"," 'electra.encoder.layer.11.attention.output.dense.weight',\n"," 'electra.encoder.layer.11.attention.output.dense.bias',\n"," 'electra.encoder.layer.11.attention.output.LayerNorm.weight',\n"," 'electra.encoder.layer.11.attention.output.LayerNorm.bias',\n"," 'electra.encoder.layer.11.intermediate.dense.weight',\n"," 'electra.encoder.layer.11.intermediate.dense.bias',\n"," 'electra.encoder.layer.11.output.dense.weight',\n"," 'electra.encoder.layer.11.output.dense.bias',\n"," 'electra.encoder.layer.11.output.LayerNorm.weight',\n"," 'electra.encoder.layer.11.output.LayerNorm.bias',\n"," 'abu_c1.fc1.weight',\n"," 'abu_c1.fc1.bias',\n"," 'abu_c1.norm.weight',\n"," 'abu_c1.norm.bias',\n"," 'senti_c1.fc1.weight',\n"," 'senti_c1.fc1.bias',\n"," 'senti_c1.norm.weight',\n"," 'senti_c1.norm.bias',\n"," 'off_c1.fc1.weight',\n"," 'off_c1.fc1.bias',\n"," 'off_c1.norm.weight',\n"," 'off_c1.norm.bias']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["model_param_name = []\n","for param in list(model.named_parameters()):\n","    if param[1].requires_grad:\n","        model_param_name.append(param[0])\n","model_param_name"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["trial = 79"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["before 79th trial\n","\n","초기화된 모델의 ALD 정확도: 56.05 %\n","초기화된 모델의 SA 정확도: 34.73 %\n","초기화된 모델의 OLI 정확도: 13.95 %\n"]}],"source":["# Pre-train Evaluation\n","abu_acc, senti_acc, off_acc, total_count = 0, 0, 0, 0\n","\n","print(f'before {trial}th trial\\n')\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # gpu가속을 위함\n","model = model.to(device)\n","model.eval()\n","\n","for data in test_dataloader:\n","  input = data[0].to(device)\n","  attn_mask = data[1].to(device)\n","  abu_true = data[2][:, 0]\n","  senti_true = data[2][:, 1]\n","  off_true = data[2][:, 2]\n","\n","  out = model(input, attention_mask = attn_mask)\n","  abu_pred = out[0]\n","  senti_pred = out[1]\n","  off_pred = out[2]  \n","\n","\n","  abu_pred = abu_pred.detach().cpu()\n","  senti_pred = senti_pred.detach().cpu()\n","  off_pred = off_pred.detach().cpu()\n","\n","  abu_acc += (abu_pred.argmax(1) == abu_true).sum().item()\n","  senti_acc += (senti_pred.argmax(1) == senti_true).sum().item()\n","  off_acc += (off_pred.argmax(1) == off_true).sum().item()\n","\n","  total_count += abu_pred.size(0)\n","\n","  # if total_count % (batch_size * 20) == 0:\n","  #   print(f'평가 진행중.. [{total_count}/{test_data_size}]')\n","  #   print(f\"학습된 모델의 중간 abussive detection 정확도: {format(abu_acc/total_count * 100, '.3f')} %\")\n","  #   print(f\"학습된 모델의 중간 sentiment analysis 정확도: {format(senti_acc/total_count * 100, '.3f')} %\")\n","  #   print(f\"학습된 모델의 중간 offensive language detection 정확도: {format(off_acc/total_count * 100, '.3f')} %\")\n","\n","\n","print(f\"초기화된 모델의 ALD 정확도: {format(abu_acc/total_count * 100, '.2f')} %\")\n","print(f\"초기화된 모델의 SA 정확도: {format(senti_acc/total_count * 100, '.2f')} %\")\n","print(f\"초기화된 모델의 OLI 정확도: {format(off_acc/total_count * 100, '.2f')} %\")"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":81154,"status":"ok","timestamp":1712911963935,"user":{"displayName":"이규진","userId":"15581271079389640736"},"user_tz":-540},"id":"cKma3MpGIwCB","outputId":"851bb355-3432-4b6a-fef9-cc404b178e0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20, Step [6400/32708], Loss: 3.4244\n","Epoch 1/20, Step [12800/32708], Loss: 3.3128\n","Epoch 1/20, Step [19200/32708], Loss: 3.6013\n","Epoch 1/20, Step [25600/32708], Loss: 3.2868\n","Epoch 1/20, Step [32000/32708], Loss: 3.4168\n","Epoch 2/20, Step [6400/32708], Loss: 3.2380\n","Epoch 2/20, Step [12800/32708], Loss: 3.2002\n","Epoch 2/20, Step [19200/32708], Loss: 3.2200\n","Epoch 2/20, Step [25600/32708], Loss: 3.4596\n","Epoch 2/20, Step [32000/32708], Loss: 3.4435\n","모델의 ALD 정확도: 51.63 %\n","모델의 SA 정확도: 32.67 %\n","모델의 OLI 정확도: 26.18 %\n","Epoch 3/20, Step [6400/32708], Loss: 3.4212\n","Epoch 3/20, Step [12800/32708], Loss: 3.3966\n","Epoch 3/20, Step [19200/32708], Loss: 3.3713\n","Epoch 3/20, Step [25600/32708], Loss: 3.3476\n","Epoch 3/20, Step [32000/32708], Loss: 3.2497\n","Epoch 4/20, Step [6400/32708], Loss: 3.3992\n","Epoch 4/20, Step [12800/32708], Loss: 3.2838\n","Epoch 4/20, Step [19200/32708], Loss: 3.6909\n","Epoch 4/20, Step [25600/32708], Loss: 3.2659\n","Epoch 4/20, Step [32000/32708], Loss: 3.3852\n","모델의 ALD 정확도: 51.35 %\n","모델의 SA 정확도: 32.84 %\n","모델의 OLI 정확도: 25.96 %\n","Epoch 5/20, Step [6400/32708], Loss: 3.4483\n","Epoch 5/20, Step [12800/32708], Loss: 3.4678\n","Epoch 5/20, Step [19200/32708], Loss: 3.3829\n","Epoch 5/20, Step [25600/32708], Loss: 3.3685\n","Epoch 5/20, Step [32000/32708], Loss: 3.2808\n","Epoch 6/20, Step [6400/32708], Loss: 3.5076\n","Epoch 6/20, Step [12800/32708], Loss: 3.3934\n","Epoch 6/20, Step [19200/32708], Loss: 3.4528\n","Epoch 6/20, Step [25600/32708], Loss: 3.4648\n","Epoch 6/20, Step [32000/32708], Loss: 3.5004\n","모델의 ALD 정확도: 51.25 %\n","모델의 SA 정확도: 32.85 %\n","모델의 OLI 정확도: 26.08 %\n","Epoch 7/20, Step [6400/32708], Loss: 3.3770\n","Epoch 7/20, Step [12800/32708], Loss: 3.2678\n","Epoch 7/20, Step [19200/32708], Loss: 3.3500\n","Epoch 7/20, Step [25600/32708], Loss: 3.1372\n","Epoch 7/20, Step [32000/32708], Loss: 3.3594\n","Epoch 8/20, Step [6400/32708], Loss: 3.3931\n","Epoch 8/20, Step [12800/32708], Loss: 3.3870\n","Epoch 8/20, Step [19200/32708], Loss: 3.2143\n","Epoch 8/20, Step [25600/32708], Loss: 3.3670\n","Epoch 8/20, Step [32000/32708], Loss: 3.2414\n","모델의 ALD 정확도: 51.54 %\n","모델의 SA 정확도: 33.20 %\n","모델의 OLI 정확도: 26.48 %\n","Epoch 9/20, Step [6400/32708], Loss: 3.5207\n","Epoch 9/20, Step [12800/32708], Loss: 3.1756\n","Epoch 9/20, Step [19200/32708], Loss: 3.2820\n","Epoch 9/20, Step [25600/32708], Loss: 3.4310\n","Epoch 9/20, Step [32000/32708], Loss: 3.1879\n","Epoch 10/20, Step [6400/32708], Loss: 3.3301\n","Epoch 10/20, Step [12800/32708], Loss: 3.4502\n","Epoch 10/20, Step [19200/32708], Loss: 3.5201\n","Epoch 10/20, Step [25600/32708], Loss: 3.3973\n","Epoch 10/20, Step [32000/32708], Loss: 3.5027\n","모델의 ALD 정확도: 51.09 %\n","모델의 SA 정확도: 32.81 %\n","모델의 OLI 정확도: 26.21 %\n","Epoch 11/20, Step [6400/32708], Loss: 3.5094\n","Epoch 11/20, Step [12800/32708], Loss: 3.4018\n","Epoch 11/20, Step [19200/32708], Loss: 3.5654\n","Epoch 11/20, Step [25600/32708], Loss: 3.4121\n","Epoch 11/20, Step [32000/32708], Loss: 3.1816\n","Epoch 12/20, Step [6400/32708], Loss: 3.6201\n","Epoch 12/20, Step [12800/32708], Loss: 3.2224\n","Epoch 12/20, Step [19200/32708], Loss: 3.4292\n","Epoch 12/20, Step [25600/32708], Loss: 3.3845\n","Epoch 12/20, Step [32000/32708], Loss: 3.2002\n","모델의 ALD 정확도: 50.81 %\n","모델의 SA 정확도: 32.77 %\n","모델의 OLI 정확도: 26.38 %\n","Epoch 13/20, Step [6400/32708], Loss: 3.3105\n","Epoch 13/20, Step [12800/32708], Loss: 3.2299\n","Epoch 13/20, Step [19200/32708], Loss: 3.2574\n","Epoch 13/20, Step [25600/32708], Loss: 3.2959\n","Epoch 13/20, Step [32000/32708], Loss: 3.4163\n","Epoch 14/20, Step [6400/32708], Loss: 3.1741\n","Epoch 14/20, Step [12800/32708], Loss: 3.3731\n","Epoch 14/20, Step [19200/32708], Loss: 3.3186\n","Epoch 14/20, Step [25600/32708], Loss: 3.4681\n","Epoch 14/20, Step [32000/32708], Loss: 3.4522\n","모델의 ALD 정확도: 51.06 %\n","모델의 SA 정확도: 32.81 %\n","모델의 OLI 정확도: 26.18 %\n","Epoch 15/20, Step [6400/32708], Loss: 3.5990\n","Epoch 15/20, Step [12800/32708], Loss: 3.3384\n","Epoch 15/20, Step [19200/32708], Loss: 3.4950\n","Epoch 15/20, Step [25600/32708], Loss: 3.4339\n","Epoch 15/20, Step [32000/32708], Loss: 3.2703\n","Epoch 16/20, Step [6400/32708], Loss: 3.3322\n","Epoch 16/20, Step [12800/32708], Loss: 3.3283\n","Epoch 16/20, Step [19200/32708], Loss: 3.2811\n","Epoch 16/20, Step [25600/32708], Loss: 3.3689\n","Epoch 16/20, Step [32000/32708], Loss: 3.5199\n","모델의 ALD 정확도: 51.26 %\n","모델의 SA 정확도: 32.76 %\n","모델의 OLI 정확도: 26.09 %\n","Epoch 17/20, Step [6400/32708], Loss: 3.4697\n","Epoch 17/20, Step [12800/32708], Loss: 3.4212\n","Epoch 17/20, Step [19200/32708], Loss: 3.3185\n","Epoch 17/20, Step [25600/32708], Loss: 3.4365\n","Epoch 17/20, Step [32000/32708], Loss: 3.1257\n","Epoch 18/20, Step [6400/32708], Loss: 3.4742\n","Epoch 18/20, Step [12800/32708], Loss: 3.2470\n","Epoch 18/20, Step [19200/32708], Loss: 3.4737\n","Epoch 18/20, Step [25600/32708], Loss: 3.3559\n","Epoch 18/20, Step [32000/32708], Loss: 3.4097\n","모델의 ALD 정확도: 51.07 %\n","모델의 SA 정확도: 32.81 %\n","모델의 OLI 정확도: 26.32 %\n","Epoch 19/20, Step [6400/32708], Loss: 3.3899\n","Epoch 19/20, Step [12800/32708], Loss: 3.3825\n","Epoch 19/20, Step [19200/32708], Loss: 3.3814\n","Epoch 19/20, Step [25600/32708], Loss: 3.4558\n","Epoch 19/20, Step [32000/32708], Loss: 3.3316\n","Epoch 20/20, Step [6400/32708], Loss: 3.4114\n","Epoch 20/20, Step [12800/32708], Loss: 3.4498\n","Epoch 20/20, Step [19200/32708], Loss: 3.2971\n","Epoch 20/20, Step [25600/32708], Loss: 3.2246\n","Epoch 20/20, Step [32000/32708], Loss: 3.2374\n","모델의 ALD 정확도: 51.16 %\n","모델의 SA 정확도: 32.87 %\n","모델의 OLI 정확도: 26.24 %\n"]}],"source":["#max_epochs = 10\n","eval_per_epoch = 2\n","# training\n","model.train()\n","abu_acc, senti_acc, off_acc, total_count = 0, 0, 0, 0\n","for epoch in range(max_epochs):\n","  num_steps = 0\n","  \n","  for batch in train_dataloader:\n","    input = batch[0].to(device)\n","    attn_mask = batch[1].to(device)\n","    abu_true = batch[2][:, 0].to(device)\n","    senti_true = batch[2][:, 1].to(device)\n","    off_true = batch[2][:, 2].to(device)\n","\n","    out = model(input, attention_mask = attn_mask)\n","\n","    abu_pred = out[0]\n","    senti_pred = out[1]\n","    off_pred = out[2]  \n","\n","\n","    abu_loss = criterion(abu_pred, abu_true)\n","    senti_loss = criterion(senti_pred, senti_true)\n","    off_loss = criterion(off_pred, off_true)\n","    \n","    loss = abu_loss + senti_loss + off_loss\n","\n","    #loss = criterion(abu_pred, abu_true)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    scheduler.step\n","    num_steps += batch_size\n","    if (num_steps) % (batch_size * 100) == 0:\n","      print(f'Epoch {epoch+1}/{max_epochs}, Step [{num_steps}/{train_data_size}], Loss: {loss.item():.4f}')\n","\n","    abu_acc += (abu_pred.argmax(1) == abu_true).sum().item()\n","    senti_acc += (senti_pred.argmax(1) == senti_true).sum().item()\n","    off_acc += (off_pred.argmax(1) == off_true).sum().item()\n","    total_count += abu_pred.size(0)\n","\n","    if max_step_per_epoch and num_steps > max_step_per_epoch:\n","      break\n","    \n","  \n","  if epoch % eval_per_epoch == eval_per_epoch-1:\n","    print(f\"모델의 ALD 정확도: {format(abu_acc/total_count * 100, '.2f')} %\")\n","    print(f\"모델의 SA 정확도: {format(senti_acc/total_count * 100, '.2f')} %\")\n","    print(f\"모델의 OLI 정확도: {format(off_acc/total_count * 100, '.2f')} %\")\n","    abu_acc, senti_acc, off_acc, total_count = 0, 0, 0, 0\n","    "]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["after 79th trial\n","\n","학습된 모델의 최종 ALD 정확도: 56.05 %\n","학습된 모델의 최종 SA 정확도: 34.73 %\n","학습된 모델의 최종 OLI 정확도: 13.95 %\n"]}],"source":["# Post-train Evaluation\n","abu_acc, senti_acc, off_acc, total_count = 0, 0, 0, 0\n","\n","print(f'after {trial}th trial\\n')\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # gpu가속을 위함\n","model = model.to(device)\n","model.eval()\n","\n","for data in test_dataloader:\n","  input = data[0].to(device)\n","  attn_mask = data[1].to(device)\n","  abu_true = data[2][:, 0]\n","  senti_true = data[2][:, 1]\n","  off_true = data[2][:, 2]\n","\n","  out = model(input, attention_mask = attn_mask)\n","  abu_pred = out[0]\n","  senti_pred = out[1]\n","  off_pred = out[2]  \n","\n","  \n","  abu_pred = abu_pred.detach().cpu()\n","  senti_pred = senti_pred.detach().cpu()\n","  off_pred = off_pred.detach().cpu()\n","\n","  abu_acc += (abu_pred.argmax(1) == abu_true).sum().item()\n","  senti_acc += (senti_pred.argmax(1) == senti_true).sum().item()\n","  off_acc += (off_pred.argmax(1) == off_true).sum().item()\n","\n","  total_count += abu_pred.size(0)\n","\n","  # if total_count % (batch_size * 20) == 0:\n","  #   print(f'평가 진행중.. [{total_count}/{test_data_size}]')\n","  #   print(f\"학습된 모델의 중간 abussive detection 정확도: {format(abu_acc/total_count * 100, '.3f')} %\")\n","  #   print(f\"학습된 모델의 중간 sentiment analysis 정확도: {format(senti_acc/total_count * 100, '.3f')} %\")\n","  #   print(f\"학습된 모델의 중간 offensive language detection 정확도: {format(off_acc/total_count * 100, '.3f')} %\")\n","\n","\n","print(f\"학습된 모델의 최종 ALD 정확도: {format(abu_acc/total_count * 100, '.2f')} %\")\n","print(f\"학습된 모델의 최종 SA 정확도: {format(senti_acc/total_count * 100, '.2f')} %\")\n","print(f\"학습된 모델의 최종 OLI 정확도: {format(off_acc/total_count * 100, '.2f')} %\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Post-train thorough Evaluation\n","TPFP_not, TP_not, TPFN_not = 0, 0, 0\n","TPFP_likely, TP_likely, TPFN_likely = 0, 0, 0\n","TPFP_off, TP_off, TPFN_off = 0, 0, 0\n","total_count = 0\n","\n","print(f'after {trial}th trial / offensive detection thorough evaluation\\n')\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # gpu가속을 위함\n","model = model.to(device)\n","model.eval()\n","\n","for data in test_dataloader:\n","  input = data[0].to(device)\n","  attn_mask = data[1].to(device)\n","  off_true = data[2][:, 2]\n","\n","  out = model(input, attention_mask = attn_mask)\n","\n","  out = out.detach().cpu()\n","  predict_index = out.argmax(1)\n","\n","  off_pred = (predict_index % 9) % 3\n","    \n","  TPFP_not += (off_pred == torch.tensor(0)).sum().item()\n","  TPFP_likely += (off_pred == torch.tensor(1)).sum().item()\n","  TPFP_off += (off_pred == torch.tensor(2)).sum().item()\n","\n","  TP_not += (off_pred * 10 == off_true).sum().item()\n","  TP_likely += (((off_pred - torch.tensor(1))*10 + torch.tensor(1)) == off_true).sum().item()\n","  TP_off += (((off_pred - torch.tensor(2)) *10 + torch.tensor(2)) == off_true).sum().item()\n","\n","  TPFN_not += (off_true == torch.tensor(0)).sum().item()\n","  TPFN_likely += (off_true == torch.tensor(1)).sum().item()\n","  TPFN_off += (off_true == torch.tensor(2)).sum().item()\n","\n","  total_count += out.size(0)\n","\n","print(TPFP_not, TP_not, TPFN_not,  '/', TPFP_likely, TP_likely, TPFN_likely, '/', TPFP_off, TP_off, TPFN_off, '/', total_count)\n","print(f\"학습된 모델의 Not 정확도: Precision {format(TP_not/TPFP_not * 100, '.2f')} % / Recall {format(TP_not/TPFN_not * 100, '.2f')} % / F1 {format((2 * TP_not/TPFP_not * 100 * TP_not/TPFN_not * 100) / (TP_not/TPFP_not * 100 + TP_not/TPFN_not * 100), '.2f')}\")\n","print(f\"학습된 모델의 Likely 정확도: Precision {format(TP_likely/TPFP_likely * 100, '.2f')} % / Recall {format(TP_likely/TPFN_likely * 100, '.2f')} % / F1 {format((2 * TP_likely/TPFP_likely * 100 * TP_likely/TPFN_likely * 100) / (TP_likely/TPFP_likely * 100 + TP_likely/TPFN_likely * 100), '.2f')}\")\n","print(f\"학습된 모델의 Offensive 정확도: Precision {format(TP_off/TPFP_off * 100, '.2f')} % / Recall {format(TP_off/TPFN_off * 100, '.2f')} % / F1 {format((2 * TP_off/TPFP_off * 100 * TP_off/TPFN_off * 100) / (TP_off/TPFP_off * 100 + TP_off/TPFN_off * 100), '.2f')}\")"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["# # 결과 잘 나온 모델 저장하기\n","# savefile_name = f'{trial}th_trial'\n","# Path = os.getcwd() # <- 로컬\n","# #Path = '/content/gdrive/MyDrive/Colab Notebooks'# <- 코랩\n","# torch.save(model.state_dict(), Path + f'/{savefile_name}.pth')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNCNe8ayRs6OYYnUxXr15gh","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"047ea13f87e24cac9a8de2b15e6b1ae9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_89a250eaa65c4eb0a749b16556b1dec9","max":467,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4205cb5af98411fa8a1346bcb430f15","value":467}},"082a56007a704911b531b31c388cea10":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ec35b2122bf453f97c4f1319d73b193":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b8e4c6c3c6d4c7fbbe24491359368dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f5d7f0499cf491f8f28c305a97d5f60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ab76aaf83c540a48c35e437cb970469":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ea8c57d705541bcbe2452a362184c88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3533324b7a9f41578022594bdac952b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"413de6e14f4c4ca6918c6a4da73344b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"419afa4fb53f454ba2a75ba00229813e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c0d7bb96d9e46b4b3b2d4ae91c92786":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cbc4b661d654faba6eed53a4f1c3311":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c009bca84fa94198bcc7484f813ba180","placeholder":"​","style":"IPY_MODEL_419afa4fb53f454ba2a75ba00229813e","value":"vocab.txt: 100%"}},"4ec3f2babc22420f9b444a33c2a1561f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3533324b7a9f41578022594bdac952b4","max":263326,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f5d7f0499cf491f8f28c305a97d5f60","value":263326}},"5d6a39fbb4e54109997b36e1ea89c066":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8ca25f545f64ca4b9d9e1e3d9ca7a00","max":61,"min":0,"orientation":"horizontal","style":"IPY_MODEL_413de6e14f4c4ca6918c6a4da73344b1","value":61}},"67a25503df62410d9be2d53a6843ee72":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b8e4c6c3c6d4c7fbbe24491359368dc","placeholder":"​","style":"IPY_MODEL_cb00bd2d99ea42d782f8a11cf3fef67e","value":" 61.0/61.0 [00:00&lt;00:00, 1.77kB/s]"}},"68228df6dc3e4431b453433f094ade57":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ab76aaf83c540a48c35e437cb970469","placeholder":"​","style":"IPY_MODEL_72a6ab83e2154eb4ba323be7b76a062e","value":"tokenizer_config.json: 100%"}},"72a6ab83e2154eb4ba323be7b76a062e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89a250eaa65c4eb0a749b16556b1dec9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a34d8583a1f242b5988f03c670e34fc7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad6b3720d9ec4d5c997072d2eea8b038":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_082a56007a704911b531b31c388cea10","placeholder":"​","style":"IPY_MODEL_d94f3cce2a5c46fb8aaa1064d0e82aab","value":" 467/467 [00:00&lt;00:00, 7.65kB/s]"}},"bb5672b789f2412bbf49a4734df87b81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ec35b2122bf453f97c4f1319d73b193","placeholder":"​","style":"IPY_MODEL_4c0d7bb96d9e46b4b3b2d4ae91c92786","value":" 263k/263k [00:00&lt;00:00, 1.47MB/s]"}},"c009bca84fa94198bcc7484f813ba180":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4197f81b72c4b5982944b5d8928f05a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4205cb5af98411fa8a1346bcb430f15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8ca25f545f64ca4b9d9e1e3d9ca7a00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb00bd2d99ea42d782f8a11cf3fef67e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd2ea341f6384982baa3f07244a4e72a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cea73f88dcae4810ab3b2085128f8b43","placeholder":"​","style":"IPY_MODEL_f27d6e04a7fd4d368e971b8750a7b320","value":"config.json: 100%"}},"cea73f88dcae4810ab3b2085128f8b43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3ab91b745f0493fb7ecfd17aa22e723":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd2ea341f6384982baa3f07244a4e72a","IPY_MODEL_047ea13f87e24cac9a8de2b15e6b1ae9","IPY_MODEL_ad6b3720d9ec4d5c997072d2eea8b038"],"layout":"IPY_MODEL_c4197f81b72c4b5982944b5d8928f05a"}},"d94f3cce2a5c46fb8aaa1064d0e82aab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"daf3ecf0f3af4c14b5f11cafddbec554":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68228df6dc3e4431b453433f094ade57","IPY_MODEL_5d6a39fbb4e54109997b36e1ea89c066","IPY_MODEL_67a25503df62410d9be2d53a6843ee72"],"layout":"IPY_MODEL_2ea8c57d705541bcbe2452a362184c88"}},"e67e20811b1b46cab49c53fd7f637cb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4cbc4b661d654faba6eed53a4f1c3311","IPY_MODEL_4ec3f2babc22420f9b444a33c2a1561f","IPY_MODEL_bb5672b789f2412bbf49a4734df87b81"],"layout":"IPY_MODEL_a34d8583a1f242b5988f03c670e34fc7"}},"f27d6e04a7fd4d368e971b8750a7b320":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
